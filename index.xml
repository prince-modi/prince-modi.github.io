<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Prince Modi</title>
    <link>http://localhost:1313/</link>
      <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <description>Prince Modi</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hua5d2116872382d6405c4fb215e02fa8e_2300_512x512_fill_lanczos_center_3.png</url>
      <title>Prince Modi</title>
      <link>http://localhost:1313/</link>
    </image>
    
    <item>
      <title>Exploring the Power of Google File System: The Distributed Storage System That Revolutionized Big Data</title>
      <link>http://localhost:1313/post/google-file-system/</link>
      <pubDate>Sat, 04 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/google-file-system/</guid>
      <description>&lt;!-- # Exploring the Power of Google File System: The Distributed Storage System That Revolutionized Big Data --&gt;
&lt;p&gt;The paper &lt;em&gt;The Google File System&lt;/em&gt; by Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung (Google) presents details of a distributed file system designed to support distributed applications and the various assumptions and design decisions that were made.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Credit:&lt;/strong&gt; &lt;a href=&#34;https://www.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;google.com&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;From the introduction of the paper, we have the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We have designed and implemented the Google File System (GFS) to meet the rapidly growing demands of Google&amp;rsquo;s data processing needs. GFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability. However, its design has been driven by key observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system design assumptions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The decisions made while designing and implementing GFS mainly focused on the fact that there was a need for a scalable distributed file system that would be used in conjunction with large distributed data-intensive applications, for example, MapReduce.&lt;/p&gt;
&lt;p&gt;The designers understood that on a file system distributed across hundreds or even thousands of machines, the chances of some computers failing would be significantly higher, so they designed the GFS with monitoring, error detection, fault tolerance, and recovery in mind.&lt;/p&gt;
&lt;p&gt;Since the file system is also designed for large data-intensive applications, the files that they would have to store would be larger than the traditional standards.&lt;/p&gt;
&lt;p&gt;It was found that the majority of the writes that the applications performed were appending the new data at the end of the file. Random writes on files were practically non-existent. Once the data was written, it was only read and that too was often only sequential reads.&lt;/p&gt;
&lt;h2 id=&#34;assumptions&#34;&gt;Assumptions&lt;/h2&gt;
&lt;p&gt;There are several core assumptions that constrain the design of GFS, and they are centered around the typical workload of GFS clients. The in-detail assumptions are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The system is built from many inexpensive commodity components that often fail.&lt;/strong&gt;&lt;br&gt;
The assumption is that on a distributed file system operating at such a large scale, the chances that at any given time some components might not be functional is really high, so they have incorporated constant monitoring, fault detection, tolerance, and recovery into the design.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The system stores a modest number of large files.&lt;/strong&gt;&lt;br&gt;
We expect a few million files, each typically 100 MB or larger in size. Multi-GB files are the common case and should be managed efficiently. Small files must be supported, but we need not optimize for them.&lt;br&gt;
GFS is designed to store a large number of large files (&amp;gt;100 MB) consisting of 64 MB chunks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The workloads primarily consist of two kinds of reads:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Large streaming reads&lt;/strong&gt; (hundreds of KBs to MBs). Successive operations from the same client often read through a contiguous region of a file.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Small random reads&lt;/strong&gt;, typically reading a few KBs at some arbitrary offset. Performance-conscious applications often batch and sort their small reads to advance steadily through the file rather than go back and forth.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The workloads also have many large, sequential writes that append data to files.&lt;/strong&gt;&lt;br&gt;
Typical operation sizes are similar to those for reads. Once written, files are seldom modified again. Small writes at arbitrary positions in a file are supported but do not have to be efficient.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;The system must efficiently implement well-defined semantics for multiple clients that concurrently append to the same file.&lt;/strong&gt;&lt;br&gt;
GFS files will typically experience highly concurrent append-heavy workloads, and it&amp;rsquo;s crucial these operations are implemented by the system efficiently.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;High sustained bandwidth is more important than low latency.&lt;/strong&gt;&lt;br&gt;
Clients tend to engage in large data processing jobs, which rely on maintaining sustained high bandwidth, more so than optimizing for individual operation latency.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;interface&#34;&gt;Interface&lt;/h2&gt;
&lt;p&gt;GFS provides an interface that supports all the usual operations that are expected from a file system such as creating, deleting, opening, closing, reading, and writing files.&lt;/p&gt;
&lt;p&gt;Apart from this, GFS also provides snapshot and record append operations. Snapshot creates a copy of a file or a directory tree at a low cost. Record append allows multiple clients to append data in the same file concurrently while ensuring the atomicity of the append operation.&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, GFS runs on a typical commodity Linux machine. A typical GFS consists of a single master and multiple chunkservers and is accessed by multiple clients. Chunkservers and clients can run on the same machines as long as the resources available on the machine permit that.&lt;/p&gt;
&lt;p&gt;Files are divided into fixed-size chunks (typically 64 MB). Each of the chunks has a 64-bit chunk handle, assigned to it by the master, which is used for identifying the chunk. For reliability, each of the chunks is replicated on 3 chunkservers by default.&lt;/p&gt;
&lt;p&gt;The metadata for the whole file system is maintained by the master in its memory. This metadata includes the namespace, access control information, the mapping from files to chunks, and the current locations of chunks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1: GFS Architecture&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It might have come to your attention that GFS only has a single master, this decision significantly reduces the complexity of the whole system since only the single master is in charge of all the chunk placement and replication decisions, instead of the case where there are multiple masters and there has to be some sort of communication between the masters to come to some agreement, which both increase the complexity and decrease the responsiveness of the whole system.&lt;/p&gt;
&lt;p&gt;But since GFS only has a single master, the designers had to make sure that the master does not become a bottleneck for the system.&lt;/p&gt;
&lt;p&gt;Clients never read and write file data through the master. Instead, a client asks the master which chunkservers it should contact. It caches this information for a limited time and interacts with the chunkservers directly for many subsequent operations.&lt;/p&gt;
&lt;p&gt;One benefit of the client caching the information of the chunk is that the master includes the information immediately following that chunk, which saves the client having to contact the master again and again for a certain period of time.&lt;/p&gt;
&lt;h2 id=&#34;metadata&#34;&gt;Metadata&lt;/h2&gt;
&lt;p&gt;The master stores three types of metadata:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The file and chunk namespaces.&lt;/li&gt;
&lt;li&gt;The mapping from files to chunks.&lt;/li&gt;
&lt;li&gt;The location of each chunk&amp;rsquo;s replicas.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of this is stored in the master&amp;rsquo;s memory. The first two types, along with certain critical metadata changes, are also kept persistent on an operation log stored in the master&amp;rsquo;s local disk and replicated on remote machines.&lt;/p&gt;
&lt;p&gt;The main benefit of keeping the metadata in memory is to decrease the time to perform these operations at the master. Certain other activities also become easier to perform in the background because of this. The master periodically scans its whole state to implement chunk garbage collection, re-replicate certain chunks in case of failure of the chunkservers storing them, and chunk migration for load and disk space balancing across the chunkservers.&lt;/p&gt;
&lt;p&gt;The master doesn&amp;rsquo;t keep a record of which chunkservers contain which chunks in persistent storage; it simply polls the chunkservers for that information at the startup and thereafter keeps itself up-to-date since the master will be the one making decisions about chunk placement. The master monitors the health of the chunkservers with regular HeartBeat messages.&lt;/p&gt;
&lt;h2 id=&#34;consistency-guarantees-by-gfs&#34;&gt;Consistency Guarantees by GFS&lt;/h2&gt;
&lt;p&gt;File namespace mutations are atomic since the master exclusively handles these mutations. The operation log present at the master defines a global total order for all of these operations.&lt;/p&gt;
&lt;p&gt;GFS supports a relaxed consistency model that works well with highly distributed applications and is also relatively simple and efficient. It is important to keep in mind that the reason GFS can work with such relaxed consistency guarantees is because of the intimate understanding of the workloads of its clients.&lt;/p&gt;
&lt;p&gt;Data mutations may be writes or record appends. A write causes data to be written at an application-specified file offset. A record append causes data (the &amp;ldquo;record&amp;rdquo;) to be appended atomically at least once even in the presence of concurrent mutations, but at an offset of GFS&amp;rsquo;s choosing… The offset is returned to the client and marks the beginning of a defined region that contains the record.&lt;/p&gt;
&lt;p&gt;As we saw earlier, clients cache the locations of certain chunks that they are currently reading from. It is possible that they may read from a stale replica before the information on that chunk replica is updated. But since most of the files are append-only, a stale replica will only return a premature end of chunk rather than outdated data. When the client retries and contacts the master, it will immediately be pointed to chunks with up-to-date data.&lt;/p&gt;
&lt;h2 id=&#34;system-interactions&#34;&gt;System Interactions&lt;/h2&gt;
&lt;p&gt;As we saw earlier, the system is designed in a way that minimizes the involvement of the master in all operations as much as possible.&lt;/p&gt;
&lt;p&gt;To handle the mutation operations, GFS uses leases. Mutation operations consist of a write or a record append operation. Each mutation operation is performed on all of the chunk&amp;rsquo;s replicas.&lt;/p&gt;
&lt;p&gt;The master grants a chunk lease to one of the chunkservers that hold a certain chunk; this chunkserver is now known as the primary.&lt;/p&gt;
&lt;p&gt;Whenever a client wants to perform a mutation operation, the client asks the master which chunkserver holds the current lease for the chunk and the locations of the other replicas.&lt;/p&gt;
&lt;p&gt;The master replies with the identity of the primary and the location of other replicas. The client caches this data. The client needs now only to contact the master in case the primary server stops responding or replies that it no longer holds the lease.&lt;/p&gt;
&lt;p&gt;The client pushes the data that it needs to write/append to all of the replicas.&lt;/p&gt;
&lt;p&gt;Once all the replicas have acknowledged receiving the data, the client sends a write request to the primary. The primary assigns an order to all the mutations that it has received from the client (possibly multiple). It applies the mutation to its local state.&lt;/p&gt;
&lt;p&gt;The primary forwards the write request to all the replicas, and each replica applies the mutations in the same order provided by the primary.&lt;/p&gt;
&lt;p&gt;Once all the replicas reply to the primary indicating that they have completed the operation, the primary replies to the client that the mutation has succeeded.&lt;/p&gt;
&lt;p&gt;Any errors encountered at any of the replicas are reported to the client. In case of errors, the write may have succeeded at the primary and an arbitrary subset of the secondary replicas. (If it had failed at the primary, it would not have been assigned a serial number and forwarded.) The client request is considered to have failed, and the modified region is left in an inconsistent state. Our client code handles such errors by retrying the failed mutation.&lt;/p&gt;
&lt;p&gt;Here one can observe the design decision to decouple the flow of data from the flow of control. Once the primary chunkserver has a lease from the master, the client or the chunkserver doesn&amp;rsquo;t need to communicate with the master, and the data can flow directly from the client to the chunkserver or vice-versa.&lt;/p&gt;
&lt;p&gt;Another aspect of this is when the control flows from the client to the primary and then to the secondaries, the data can be pushed linearly across a chain of chunkservers in a pipelined fashion, ensuring that the network capacity of all the machines is utilized properly.&lt;/p&gt;
&lt;p&gt;Thus, decoupling the flow of data from the flow of control adds an element of network optimization.&lt;/p&gt;
&lt;h2 id=&#34;stale-replica-detection&#34;&gt;Stale Replica Detection&lt;/h2&gt;
&lt;p&gt;Chunk replicas on a chunkserver might become stale if that chunkserver is down during some mutation on the chunks it contains. For each chunk, the master maintains a chunk version number to distinguish between up-to-date and stale replicas.&lt;/p&gt;
&lt;p&gt;Whenever the master grants a new lease on a chunk, it increases the chunk version number and informs the up-to-date replicas. The master and these replicas all record the new version number in their persistent state.&lt;/p&gt;
&lt;p&gt;This ensures that any replica that was not updated while the mutation happened would contain an older version number. So, when it comes back up and reports its chunks and their associated version numbers, the master can detect that the chunks it contains are stale.&lt;/p&gt;
&lt;p&gt;The master removes these stale replicas during its regular garbage collection. Before that, the master considers them to not exist at all, and when any client requests chunk information, these stale replicas are not reported. As a safeguard, the master also provides the client with the latest chunk version number so that the client can verify that it is always accessing up-to-date data.&lt;/p&gt;
&lt;h2 id=&#34;key-takeaways&#34;&gt;Key Takeaways&lt;/h2&gt;
&lt;p&gt;There are many remarkable elements of the Google File System, some of the important ones I would like to highlight are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Demonstrating that large-scale highly-distributed operations such as this distributed file system can be supported by the means of regular commodity hardware.&lt;/li&gt;
&lt;li&gt;Separation of data flow from control flow, allowing better utilization of the network and also making the single master architecture feasible.&lt;/li&gt;
&lt;li&gt;Aggressively designing all elements of the system for specific client workloads, which makes it possible to have different or simpler consistency guarantees.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Exploring the Power of Google Spanner for Distributed Transaction Processing</title>
      <link>http://localhost:1313/post/google-spanner/</link>
      <pubDate>Tue, 05 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/google-spanner/</guid>
      <description>&lt;p&gt;This article is my understanding of distributed transactions and various aspects of &lt;strong&gt;Spanner&lt;/strong&gt;, such as its structure, how it handles transactions like Read-Write and Read-Only Transactions, and the &lt;strong&gt;TrueTime API&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;distributed-transactions&#34;&gt;Distributed Transactions&lt;/h2&gt;
&lt;p&gt;Transactions package multiple operations on data records to ensure they execute as a single unit, even in the event of failure. These guarantees are often referred to as &lt;strong&gt;ACID&lt;/strong&gt; properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Atomic&lt;/strong&gt;: All-or-nothing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistent&lt;/strong&gt;: The system must remain in a valid state before and after&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Isolated&lt;/strong&gt;: Each transaction appears to run alone&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Durable&lt;/strong&gt;: Changes persist despite failures&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;need-for-distributed-transactions&#34;&gt;Need for Distributed Transactions&lt;/h2&gt;
&lt;p&gt;Large databases often contain millions of records and are &lt;strong&gt;sharded&lt;/strong&gt; across machines (e.g., one shard contains rows A–N, another O–Z) to improve performance. When a transaction spans multiple shards, we need &lt;strong&gt;concurrency control&lt;/strong&gt; and &lt;strong&gt;commit protocols&lt;/strong&gt; to preserve ACID guarantees.&lt;/p&gt;
&lt;p&gt;Spanner addresses this by using &lt;strong&gt;Two-Phase Locking (2PL)&lt;/strong&gt; and &lt;strong&gt;Two-Phase Commit (2PC)&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;spanner-architecture&#34;&gt;Spanner Architecture&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;Spanner deployment&lt;/strong&gt; is called a &lt;strong&gt;universe&lt;/strong&gt;. It is composed of multiple &lt;strong&gt;zones&lt;/strong&gt;, each with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;zonemaster&lt;/strong&gt; that assigns data to spanservers&lt;/li&gt;
&lt;li&gt;Between 100 and several thousand &lt;strong&gt;spanservers&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each spanserver manages &lt;strong&gt;100–1000 tablets&lt;/strong&gt;, which are sharded partitions of tables based on primary keys.&lt;/p&gt;
&lt;p&gt;To support replication, Spanner:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implements a &lt;strong&gt;Paxos state machine&lt;/strong&gt; per tablet&lt;/li&gt;
&lt;li&gt;Replicates tablets across spanservers using &lt;strong&gt;Paxos groups&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Handles concurrency control via a &lt;strong&gt;lock table&lt;/strong&gt; at the Paxos leader&lt;/li&gt;
&lt;li&gt;Uses a &lt;strong&gt;transaction manager&lt;/strong&gt; to coordinate multi-tablet transactions&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;truetime-api&#34;&gt;TrueTime API&lt;/h2&gt;
&lt;p&gt;Spanner relies on the &lt;strong&gt;TrueTime API&lt;/strong&gt; to support external consistency and concurrency control.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TrueTime returns an interval: &lt;code&gt;TTinterval = [earliest, latest]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TT.now()&lt;/code&gt; returns the interval during which the call occurred&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TT.after(t)&lt;/code&gt; returns true if &lt;code&gt;t&lt;/code&gt; has definitely passed&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TT.before(t)&lt;/code&gt; returns true if &lt;code&gt;t&lt;/code&gt; has definitely not yet occurred&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TrueTime uses &lt;strong&gt;GPS&lt;/strong&gt; and &lt;strong&gt;atomic clocks&lt;/strong&gt;, each with different failure modes. Each data center has &lt;strong&gt;time master machines&lt;/strong&gt;, and each machine runs a &lt;strong&gt;timeslave daemon&lt;/strong&gt; that polls these masters.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In production, the uncertainty bound ε (epsilon) is typically 1–7 ms, representing half the width of the TTinterval.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;transactions-in-spanner&#34;&gt;Transactions in Spanner&lt;/h2&gt;
&lt;h3 id=&#34;read-write-transactions&#34;&gt;Read-Write Transactions&lt;/h3&gt;
&lt;p&gt;Spanner uses &lt;strong&gt;Two-Phase Locking (2PL)&lt;/strong&gt; and &lt;strong&gt;Two-Phase Commit (2PC)&lt;/strong&gt; for distributed read-write transactions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The coordinator gathers:
&lt;ul&gt;
&lt;li&gt;Prepared timestamps from non-coordinators&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TTcommit&lt;/code&gt;, the commit time from the client&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;It then chooses a commit timestamp that is:
&lt;ul&gt;
&lt;li&gt;Greater than all prepared timestamps&lt;/li&gt;
&lt;li&gt;Greater than &lt;code&gt;TTcommit.latest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Greater than any earlier transaction timestamps&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Spanner performs a &lt;strong&gt;commit wait&lt;/strong&gt; to ensure this timestamp is safely in the past before finalizing the commit.&lt;/p&gt;
&lt;h3 id=&#34;read-only-transactions&#34;&gt;Read-Only Transactions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;If all required keys reside within a &lt;strong&gt;single Paxos group&lt;/strong&gt;, the leader assigns the &lt;strong&gt;last committed write timestamp&lt;/strong&gt; as the transaction timestamp, minimizing wait time.&lt;/li&gt;
&lt;li&gt;If keys span &lt;strong&gt;multiple Paxos groups&lt;/strong&gt;, the timestamp is set to &lt;code&gt;TT.now().latest&lt;/code&gt;, requiring a small delay until this time safely passes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Read-only transactions can be served from &lt;strong&gt;sufficiently up-to-date replicas&lt;/strong&gt;, allowing for &lt;strong&gt;non-blocking and lock-free reads&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Spanner blends concepts from database and distributed systems research:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From &lt;strong&gt;databases&lt;/strong&gt;: SQL-like interface, relational schema, transactions&lt;/li&gt;
&lt;li&gt;From &lt;strong&gt;systems&lt;/strong&gt;: Scalability, fault tolerance, sharding, replication, and global distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks to the &lt;strong&gt;TrueTime API&lt;/strong&gt;, Spanner achieves strong guarantees around &lt;strong&gt;external consistency&lt;/strong&gt;, &lt;strong&gt;lock-free read-only transactions&lt;/strong&gt;, and &lt;strong&gt;non-blocking reads in the past&lt;/strong&gt;—demonstrating that precise time semantics are practical and powerful in distributed systems.&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Towards a Modular Federated Learning Framework on Edge Devices</title>
      <link>http://localhost:1313/publication/conference-poster/hipc-srs-2023/</link>
      <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-poster/hipc-srs-2023/</guid>
      <description>&lt;h3 id=&#34;framework-architecture&#34;&gt;Framework Architecture&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Figure 1.&#34; srcset=&#34;
               /media/publication/conference-paper/hipcsrs_2023_fedml_hu52a6e8e2239d9922f3d08e43da9f0811_32522_49de2d2ae628f3fa17585fc824d3b5bb.webp 400w,
               /media/publication/conference-paper/hipcsrs_2023_fedml_hu52a6e8e2239d9922f3d08e43da9f0811_32522_cee08d468bfe6c060d7ba31532f26f24.webp 760w,
               /media/publication/conference-paper/hipcsrs_2023_fedml_hu52a6e8e2239d9922f3d08e43da9f0811_32522_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;http://localhost:1313/media/publication/conference-paper/hipcsrs_2023_fedml_hu52a6e8e2239d9922f3d08e43da9f0811_32522_49de2d2ae628f3fa17585fc824d3b5bb.webp&#34;
               width=&#34;456&#34;
               height=&#34;178&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;press&#34;&gt;Press&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://2023.hipc.org/srs-2023/#:~:text=Towards%20a%20Modular%20Federated%20Learning%20Framework%20on%20Edge%20Devices&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Towards a Modular Federated Learning Framework on Edge Devices&amp;rdquo;&lt;/a&gt; at HiPC 2023 Student Research Symposium&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Towards Collision Avoidance for UAVs to Guide the Visually Impaired</title>
      <link>http://localhost:1313/publication/conference-poster/iros-lb-2023/</link>
      <pubDate>Thu, 10 Aug 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-poster/iros-lb-2023/</guid>
      <description>&lt;!-- ### Framework Architecture --&gt;
&lt;!-- ![Figure 1.](publication\conference-paper\hipcsrs_2023_fedml.png) --&gt;
&lt;!-- ### Press
* [&#34;Towards a Modular Federated Learning Framework on Edge Devices&#34;](https://2023.hipc.org/srs-2023/#:~:text=Towards%20a%20Modular%20Federated%20Learning%20Framework%20on%20Edge%20Devices) at HiPC 2023 Student Research Symposium --&gt;
</description>
    </item>
    
    <item>
      <title>Household displacement after disasters</title>
      <link>http://localhost:1313/project/household-displacement/</link>
      <pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/household-displacement/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For a review on household displacement and return after disasters, please refer to my &lt;a href=&#34;https://doi.org/10.1061/NHREFO.NHENG-1930&#34; target=&#34;_blank&#34;&gt;open access paper&lt;i class=&#34;ai ai-open-access ml-1&#34;&gt;&lt;/i&gt;&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Over 265 million people were displaced due to disasters between 2008 and 2018&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. In the forthcoming years, the annual number displaced is expected to increase, driven by poorly-managed urban growth in hazard-prone areas&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; and potentially exacerbated by climate change&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. Despite this scale of human impact, most disaster risk assessments focus on direct economic losses, a metric that often highlights the wealthiest as the most at-risk. However, the reality of disasters is that the poor are disproportionately affected&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;, and mitigations informed primarily by economic loss may deepen existing inequalities. This research proposes to quantify disaster-induced displacement; a more equitable risk metric to depict the human toll of disasters.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-key-definitions-and-the-scope-the-highlighted-labels-indicate-the-areas-considered-in-this-review-labels-below-the-highlighted-labels-are-subsets-of-that-category&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;project/household-displacement/scope.png&#34; alt=&#34;Key definitions and the scope. The highlighted labels indicate the areas considered in this review. Labels below the highlighted labels are subsets of that category.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Key definitions and the scope. The highlighted labels indicate the areas considered in this review. Labels below the highlighted labels are subsets of that category.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;research-themes&#34;&gt;Research themes&lt;/h2&gt;
&lt;h3 id=&#34;the-importance-of-duration&#34;&gt;The importance of duration&lt;/h3&gt;
&lt;p&gt;Most statistics regarding population displacement following a disaster event provide single snapshot values, often representing a peak estimate during the emergency phase. However, the duration of displacement is essential for understanding the human impact. For example, large- scale displacement in the form of evacuations before a storm can save lives and be followed by mass return shortly afterward. In contrast, a devastating event such as an earthquake could damage or destroy a significant proportion of the residential building stock, causing occupants to seek alternative accommodations for months to years. Not only does this type of protracted displacement pose a significant disruption to the livelihoods of affected households (e.g., lost income, interrupted education), but the consequences can ripple out into the larger community (e.g., outmigration and urban blight, lost economic production). Therefore, a key objective of this research is to refine our understanding of household displacement duration in disasters.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-timeline-representing-displacement-duration-alongside-key-phases-of-disaster-management-and-recovery&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;project/household-displacement/timeline.png&#34; alt=&#34;Timeline representing displacement duration alongside key phases of disaster management and recovery.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Timeline representing displacement duration alongside key phases of disaster management and recovery.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;determinants-of-household-return&#34;&gt;Determinants of household return&lt;/h3&gt;
&lt;p&gt;Disasters are life events that can subject households to key decision points, such as: whether to evacuate, where to seek shelter, whether to return/wait/relocate, and whether to stay or resettle. From a &lt;a href=&#34;http://localhost:1313/publication/journal-article/2024-household-displacement-in-disasters-review/&#34;&gt;literature review&lt;/a&gt; of household return after disasters, the following categories of determinants have been identified.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Category&lt;/th&gt;
&lt;th&gt;Determinants of return&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;fa-solid fa-house-chimney-crack&#34;&gt;&lt;/i&gt;&lt;/td&gt;
&lt;td&gt;Physical damage to the built environment&lt;/td&gt;
&lt;td&gt;&lt;ul&gt;&lt;li&gt;Habitability of housing (damage, weather, utilities)&lt;/li&gt;&lt;li&gt;Housing type&lt;/li&gt;&lt;li&gt;Community damage&lt;/li&gt;&lt;li&gt;Reconstruction progress&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;fa-solid fa-users&#34;&gt;&lt;/i&gt;&lt;/td&gt;
&lt;td&gt;Psychological &amp;amp; social phenomena&lt;/td&gt;
&lt;td&gt;&lt;ul&gt;&lt;li&gt;Acceleration of ongoing trends&lt;/li&gt;&lt;li&gt;Attachment to place&lt;/li&gt;&lt;li&gt;Social capital (networks, family and friends)&lt;/li&gt;&lt;li&gt;Perceived risk&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;fa-solid fa-id-card&#34;&gt;&lt;/i&gt;&lt;/td&gt;
&lt;td&gt;Household demographics&lt;/td&gt;
&lt;td&gt;&lt;ul&gt;&lt;li&gt;Socioeconomic status (e.g., income level)&lt;/li&gt;&lt;li&gt;Housing and land tenure&lt;/li&gt;&lt;li&gt;Race/ethnicity/caste&lt;/li&gt;&lt;li&gt;Age&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;i class=&#34;fa-solid fa-building-columns&#34;&gt;&lt;/i&gt;&lt;/td&gt;
&lt;td&gt;Pre- and post-disaster policies&lt;/td&gt;
&lt;td&gt;&lt;ul&gt;&lt;li&gt;Pre-existing housing conditions (e.g., vacancies)&lt;/li&gt;&lt;li&gt;Housing reconstruction approach&lt;/li&gt;&lt;li&gt;Other disaster assistance policies&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;the-role-of-housing-damage&#34;&gt;The role of housing damage&lt;/h3&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For more on the role of housing damage in population displacement predictions, please refer to my &lt;a href=&#34;https://doi.org/10.26443/seismica.v3i2.1374&#34; target=&#34;_blank&#34;&gt;open access paper&lt;i class=&#34;ai ai-open-access ml-1&#34;&gt;&lt;/i&gt;&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Disaster literature offers a clear consensus that housing damage is a primary driver of household displacement of disasters, both for initial displacement and longer-term displacement. However, additional factors (e.g., place attachment and housing tenure) have more recently been proposed as highly influential for household return in the recovery phase. Despite the range of factors beyond damage that have been proposed to influence household return, standard practice in disaster risk analysis is to solely consider housing damage. That is, the number of destroyed homes is multiplied by the average household size to yield an estimate of the displaced population.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-an-illustration-of-the-conventional-practice-for-estimating-population-displacement-after-disaster-events&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;project/household-displacement/conventional_practice.png&#34; alt=&#34;A graphical representation of the conventional practice for estimating population displacement after disasters: Displacement population = Destroyed houses × Average household size.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      An illustration of the conventional practice for estimating population displacement after disaster events.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;I benchmarked predictions of household displacement based solely on housing damage to understand the extent to which such simplified models can explain the phenomenon. The scenario model estimates showed some promise to predict potential long-term housing needs. However, quantifying displacement duration remained a clear challenge as official reports lacked this information and model estimates similarly lacked a time component. Mobile location data could theoretically fill the data gap on duration, but the benchmarking results indicate that further investigation is required on such data-driven methods.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-benchmarking-results-for-displacement-estimates-using-a-scenario-risk-analysis-that-only-considers-housing-damage-green-versus-official-reports-and-mobile-location-data-based-estimates&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;project/household-displacement/benchmarking.png&#34; alt=&#34;Benchmarking results for displacement estimates using a scenario risk analysis that only considers housing damage (green) versus official reports and mobile location data-based estimates.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Benchmarking results for displacement estimates using a scenario risk analysis that only considers housing damage (green) versus official reports and mobile location data-based estimates.
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The full results of the benchmarking study are available in a &lt;a href=&#34;http://localhost:1313/publication/journal-article/2024-benchmarking-displacement-earthquakes/&#34;&gt;journal paper&lt;/a&gt; and a &lt;a href=&#34;http://localhost:1313/publication/conference-paper/2023-benchmarking-displacement-earthquakes/&#34;&gt;conference paper&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;predicting-displacement-durations&#34;&gt;Predicting displacement durations&lt;/h3&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    For more on displacement duration and return predictions, please refer to my &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/full/10.1111/risa.17710&#34; target=&#34;_blank&#34;&gt;open access paper&lt;i class=&#34;ai ai-open-access ml-1&#34;&gt;&lt;/i&gt;&lt;/a&gt;.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;According to new data from the United States Household Pulse Survey (HPS), approximtely 1.1% of households have reported being displaced in recent disasters. However, the rates of disaster displacement vary widely state-by-state.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-percentage-of-households-displaced-by-state-according-to-the-united-states-household-pulse-survey-based-on-all-available-survey-datawhere-displacement-is-included-through-july-2024&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;A map of the United States where the percent of households displacement due to disasters is visualized state-by-state.&#34; srcset=&#34;
               /media/publication/journal-article/2025_hps_displacement_hu989370b19b479fcb2dda298a899a024f_5829075_c6a0766297f417bc15bb68dcac597aa3.webp 400w,
               /media/publication/journal-article/2025_hps_displacement_hu989370b19b479fcb2dda298a899a024f_5829075_84194397b54980cbb704b2f437572fd9.webp 760w,
               /media/publication/journal-article/2025_hps_displacement_hu989370b19b479fcb2dda298a899a024f_5829075_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;http://localhost:1313/media/publication/journal-article/2025_hps_displacement_hu989370b19b479fcb2dda298a899a024f_5829075_c6a0766297f417bc15bb68dcac597aa3.webp&#34;
               width=&#34;760&#34;
               height=&#34;484&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Percentage of households displaced by state according to the United States Household Pulse Survey (based on all available survey datawhere displacement is included through July 2024).
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The vast majority of displaced households returned quickly: 43% within a week and an additional 23% within a month. However, others faced more protracted displacement: 20% took longer than one month to return and 14% had not returned by the time of the survey.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-percentage-of-displaced-households-households-that-took-longer-than-one-month-to-return-according-to-the-united-states-household-pulse-survey-based-on-all-available-survey-datawhere-displacement-is-included-through-july-2024&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;project/household-displacement/hps_protracted.png&#34; alt=&#34;A map of the United States where the proportion of households that took beyond one month to return is visualized state-by-state.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Percentage of displaced households households that took longer than one month to return according to the United States Household Pulse Survey (based on all available survey datawhere displacement is included through July 2024).
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The availability of microdata from the HPS allows us to explore trends between displacement duration and return outcomes with potentially relevant factors such as: property damage, lifeline disruption, household demographics, and area-based attributes. To explore these trends, please refer to my &lt;a href=&#34;https://hps.nicolepaul.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;interactive dashboard&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-preview-of-the-interactive-dashboard-httpshpsnicolepaulio&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;project/household-displacement/dashboard.png&#34; alt=&#34;A screenshot of the interactive dashboard.&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Preview of the interactive dashboard: &lt;a href=&#34;https://hps.nicolepaul.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://hps.nicolepaul.io/&lt;/a&gt;
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;With the microdata, we can additionally fit predictive models and evaluate their performance. In our study, we propose three alternate models, which range in complexity and predictive power:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TreeP:&lt;/strong&gt; A classification tree model that predicts return outcomes with a minimum number of predictors related to physical factors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;TreeP&amp;amp;S:&lt;/strong&gt; A classification tree model that predicts return outcomes with a minimum number of predictors related to physical &lt;em&gt;and&lt;/em&gt; socioeconomic factors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;ForestP&amp;amp;S:&lt;/strong&gt; A random forest model that predicts return outcomes considering all predictions related to physical and socioeconomic factors.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;strong&gt;ForestP&amp;amp;S&lt;/strong&gt; model additionally allows us to highlight the importance of different physical and socioeconomic factors to predictions of displacement duration and return. These model explanations confirm that property damage is a primary driver of displacement outcomes. However, they also indicate that some socioeconomic factors are critical to consider, such as a household&amp;rsquo;s tenure status and income level. Additionally, some factors (e.g., physical immobility, household sizes of 8+, educational attainment levels of less than high school) were associated with more negative outcomes.&lt;/p&gt;
&lt;h2 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;This research is partly funded by the University College London Overseas Research Scholarship (ORS) and the Willis Towers Watson Research Network.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;IDMC. 2019. “Disaster Displacement - A Global Review, 2008-2018.” &lt;a href=&#34;https://www.internal-displacement.org/publications/disaster-displacement-a-global-review&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.internal-displacement.org/publications/disaster-displacement-a-global-review&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;IDMC. 2017. “Global Disaster Displacement Risk - A Baseline for Future Work.” &lt;a href=&#34;https://www.internal-displacement.org/publications/global-disaster-displacement-risk-a-baseline-for-future-work&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.internal-displacement.org/publications/global-disaster-displacement-risk-a-baseline-for-future-work&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;IPCC, ed. 2012. “Summary for Policymakers.” In Managing the Risks of Extreme Events and Disasters to Advance Climate Change Adaptation, 1st ed. Cambridge University Press. &lt;a href=&#34;https://doi.org/10.1017/CBO9781139177245&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1017/CBO9781139177245&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;Hallegatte, Stéphane, Adrien Vogt-Schilb, Julie Rozenberg, Mook Bangalore, and Chloé Beaudet. 2020. “From Poverty to Disaster and Back: A Review of the Literature.” Economics of Disasters and Climate Change 4 (1): 223–47. &lt;a href=&#34;https://doi.org/10.1007/s41885-020-00060-5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1007/s41885-020-00060-5&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Modeling global earthquake risk</title>
      <link>http://localhost:1313/project/global-earthquake-model/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/global-earthquake-model/</guid>
      <description>&lt;p&gt;For more information on the Global Earthquake Model (GEM) Foundation&amp;rsquo;s Global Seismic Risk model, please refer to their &lt;a href=&#34;https://www.globalquakemodel.org/products&#34; target=&#34;_blank&#34;&gt;Products&lt;/a&gt; page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional recovery and resilience</title>
      <link>http://localhost:1313/project/functional-recovery-redi/</link>
      <pubDate>Sat, 01 Jun 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/functional-recovery-redi/</guid>
      <description>&lt;p&gt;For more information about Arup&amp;rsquo;s work on functional recovery and resilience, please refer to their &lt;a href=&#34;https://www.redi.arup.com/&#34; target=&#34;_blank&#34;&gt;REDi Rating System&lt;/a&gt; website.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
